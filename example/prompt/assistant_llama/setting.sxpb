
; Newlines are included after <|eot_id|> to make the chat easier to read,
; but Llama 3 instruct prompt format does not actually include them.
(chat_prefixes (())
 (m
  (prefix "<|start_header_id|>user<|end_header_id|>\n\n")
  (suffix "<|eot_id|>\n")
 )
 (m
  (prefix "<|start_header_id|>assistant<|end_header_id|>\n\n")
  (suffix "<|eot_id|>\n")
 )
)

(x_priming "priming.txt")
(x_rolling "rolling.txt")
(o_rolling "../../../bld/example/prompt/assistant_llama.txt")

; No starting space.
(startspace_on +false)

; 10 reasonably-long sentences at a time.
(sentence_limit 10)
(sentence_token_limit 100)

; Limit context to avoid blowing up RAM on large context models.
(model_token_limit 8000)

(language
 (substitution
  (special_tokens (())
   (() (alias "<|start_header_id|>"))
   (() (alias "<|end_header_id|>"))
   (() (alias "<|eot_id|>"))
  )
 )
 ((infer_via sampling)
  (adjust_thru (())
   (temperature 0.7)
  )
 )
)
